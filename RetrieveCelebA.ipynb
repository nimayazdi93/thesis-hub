{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import json  \n",
    "from math import sqrt   \n",
    "from SSA import SSA_H_Plus\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from termcolor import colored\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16,preprocess_input\n",
    "import keras.preprocessing as preprocessing\n",
    "from keras.models import Model\n",
    "from keras.utils import load_img \n",
    "import numpy as np\n",
    "import tensorflow as tf  \n",
    "import saliency.core as saliency\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import PIL.Image \n",
    "import cv2\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self) :\n",
    "        base_model=VGG16(weights='vgg16_weights.h5') \n",
    "        self.model=Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
    "    def extract(self,img_path):\n",
    "        img = load_img(img_path, target_size=(224, 224)) \n",
    "        img=img.convert('RGB')\n",
    "        x=preprocessing.image.image_utils.img_to_array(img)\n",
    "        x=np.expand_dims(x,axis=0)\n",
    "        x=preprocess_input(x)\n",
    "        feature=self.model.predict(x)[0]\n",
    "        return feature/np.linalg.norm(feature)\n",
    "    def extract_by_array(self,img_array): \n",
    "        x=np.expand_dims(img_array,axis=0)\n",
    "        x=preprocess_input(x)\n",
    "        feature=self.model.predict(x)[0]\n",
    "        return feature/np.linalg.norm(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Saliency:\n",
    "    def __init__(self) :\n",
    "        m = VGG16(weights='vgg16_weights.h5')\n",
    "        conv_layer = m.get_layer('block5_pool')\n",
    "        self.model = Model([m.inputs], [conv_layer.output, m.output])\n",
    "        \n",
    "        self.class_idx_str = 'class_idx_str'\n",
    "    def LoadImage(self,file_path):\n",
    "        im = Image.open(file_path)\n",
    "        im = im.resize((224,224))\n",
    "        im = np.asarray(im)\n",
    "        return im\n",
    "    def PreprocessImage(self,im):\n",
    "        im = preprocess_input(im)\n",
    "        return im\n",
    "    def call_model_function(self,images, call_model_args=None, expected_keys=None):\n",
    "        target_class_idx =  call_model_args[self.class_idx_str]\n",
    "        images = tf.convert_to_tensor(images)\n",
    "        with tf.GradientTape() as tape:\n",
    "            if expected_keys==[saliency.base.INPUT_OUTPUT_GRADIENTS]:\n",
    "                tape.watch(images)\n",
    "                _, output_layer = self.model(images)\n",
    "                output_layer = output_layer[:,target_class_idx]\n",
    "                gradients = np.array(tape.gradient(output_layer, images))\n",
    "                return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n",
    "            else:\n",
    "                conv_layer, output_layer = self.model(images)\n",
    "                gradients = np.array(tape.gradient(output_layer, conv_layer))\n",
    "                return {saliency.base.CONVOLUTION_LAYER_VALUES: conv_layer,\n",
    "                        saliency.base.CONVOLUTION_OUTPUT_GRADIENTS: gradients}\n",
    "    \n",
    "    def GetSaliency(self,input,trs):\n",
    "        im_orig = self.LoadImage(input)\n",
    "        im = self.PreprocessImage(im_orig)\n",
    "        _, predictions = self.model(np.array([im]))\n",
    "        prediction_class = np.argmax(predictions[0])\n",
    "        call_model_args = {self.class_idx_str: prediction_class}\n",
    "        xrai_object = saliency.XRAI()\n",
    "        xrai_attributions = xrai_object.GetMask(im, self.call_model_function, call_model_args, batch_size=10)\n",
    "        mask = xrai_attributions >= np.percentile(xrai_attributions, trs)\n",
    "        im_mask = np.array(im_orig)\n",
    "        im_mask[~mask] = 0\n",
    "        # plt.imshow(mask)\n",
    "        # plt.show()\n",
    "        X_True=[]\n",
    "        Y_True=[]\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        for i in range(mask.shape[0]): \n",
    "            for j in range(mask.shape[1]):\n",
    "                if(mask[i][j]):\n",
    "                    X_True.append(i)\n",
    "                    Y_True.append(j)\n",
    "        X_True=list( dict.fromkeys(X_True) )\n",
    "        Y_True=list(dict.fromkeys(Y_True))\n",
    "        \n",
    "        Xmin=min(X_True)\n",
    "        XMax=max(X_True)\n",
    "        Ymin=min(Y_True)\n",
    "        YMax=max(Y_True)\n",
    "        # im_mask = np.array(im_orig)\n",
    "        # im_mask[~mask] = 0\n",
    "\n",
    "        # im_mask=im_mask[Xmin:XMax,Ymin:YMax]  \n",
    "\n",
    "        # return im_mask\n",
    "        return im_orig[Xmin:XMax,Ymin:YMax]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CelebA_Annotation=pd.read_csv('data-set/celeba/Clean/Identity_CelebA.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNameAndClass(imgPath): \n",
    "    img_path_str=str(imgPath)\n",
    "    img_path_splitted= img_path_str.split(\"/\")\n",
    "    ImageName=img_path_splitted[len(img_path_splitted)-1].replace(' ','')\n",
    "    \n",
    "    ThisName=CelebA_Annotation[CelebA_Annotation['Image']==ImageName].head(1)\n",
    "    return_value=[str(ThisName['Identity'].values[0]),str(ImageName)] \n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_dogs=[str(x) for x in sio.loadmat('cached-data/new/celeba/img_path_celeba.mat')['img_path_obj']]\n",
    "SSA_features=[x for x in sio.loadmat('cached-data/new/celeba/ssa_features_celeba.mat')['ssa_features']]\n",
    "img_names=[GetNameAndClass(x)[1] for x in img_path_dogs] \n",
    "img_folders=[GetNameAndClass(x)[0] for x in img_path_dogs]  \n",
    "all_results=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe=FeatureExtractor() \n",
    "slc=Saliency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_point=int(len(img_names)*.1)\n",
    "split_point=100\n",
    "count_of_results=5\n",
    "training, test = img_names[split_point:], img_names[:split_point] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non Saliency part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "4818\n",
      "output:\n",
      "\u001b[31m9586\u001b[0m\n",
      "\u001b[31m3830\u001b[0m\n",
      "\u001b[31m9641\u001b[0m\n",
      "\u001b[31m6626\u001b[0m\n",
      "\u001b[31m193\u001b[0m\n",
      "--------\n",
      "input:\n",
      "227\n",
      "output:\n",
      "\u001b[31m193\u001b[0m\n",
      "\u001b[31m1878\u001b[0m\n",
      "\u001b[31m193\u001b[0m\n",
      "\u001b[31m8865\u001b[0m\n",
      "\u001b[31m3784\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3658\n",
      "output:\n",
      "\u001b[31m2168\u001b[0m\n",
      "\u001b[31m9546\u001b[0m\n",
      "\u001b[31m7932\u001b[0m\n",
      "\u001b[31m9586\u001b[0m\n",
      "\u001b[31m7453\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6480\n",
      "output:\n",
      "\u001b[31m3668\u001b[0m\n",
      "\u001b[31m3668\u001b[0m\n",
      "\u001b[31m2346\u001b[0m\n",
      "\u001b[31m7229\u001b[0m\n",
      "\u001b[32m6480\u001b[0m\n",
      "--------\n",
      "input:\n",
      "9701\n",
      "output:\n",
      "\u001b[31m5703\u001b[0m\n",
      "\u001b[31m249\u001b[0m\n",
      "\u001b[31m3780\u001b[0m\n",
      "\u001b[31m4469\u001b[0m\n",
      "\u001b[31m5703\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7118\n",
      "output:\n",
      "\u001b[31m1558\u001b[0m\n",
      "\u001b[31m132\u001b[0m\n",
      "\u001b[31m2321\u001b[0m\n",
      "\u001b[31m6617\u001b[0m\n",
      "\u001b[31m7299\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3784\n",
      "output:\n",
      "\u001b[32m3784\u001b[0m\n",
      "\u001b[32m3784\u001b[0m\n",
      "\u001b[31m2896\u001b[0m\n",
      "\u001b[31m2896\u001b[0m\n",
      "\u001b[32m3784\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3226\n",
      "output:\n",
      "\u001b[31m5544\u001b[0m\n",
      "\u001b[31m6031\u001b[0m\n",
      "\u001b[31m7665\u001b[0m\n",
      "\u001b[31m3871\u001b[0m\n",
      "\u001b[31m5703\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6515\n",
      "output:\n",
      "\u001b[31m1785\u001b[0m\n",
      "\u001b[31m3464\u001b[0m\n",
      "\u001b[31m3464\u001b[0m\n",
      "\u001b[31m1375\u001b[0m\n",
      "\u001b[31m1375\u001b[0m\n",
      "--------\n",
      "input:\n",
      "4069\n",
      "output:\n",
      "\u001b[31m227\u001b[0m\n",
      "\u001b[31m2999\u001b[0m\n",
      "\u001b[31m7932\u001b[0m\n",
      "\u001b[31m2570\u001b[0m\n",
      "\u001b[31m7499\u001b[0m\n",
      "--------\n",
      "input:\n",
      "5703\n",
      "output:\n",
      "\u001b[32m5703\u001b[0m\n",
      "\u001b[32m5703\u001b[0m\n",
      "\u001b[31m5327\u001b[0m\n",
      "\u001b[32m5703\u001b[0m\n",
      "\u001b[32m5703\u001b[0m\n",
      "--------\n",
      "input:\n",
      "4518\n",
      "output:\n",
      "\u001b[31m2390\u001b[0m\n",
      "\u001b[31m2390\u001b[0m\n",
      "\u001b[32m4518\u001b[0m\n",
      "\u001b[31m3668\u001b[0m\n",
      "\u001b[32m4518\u001b[0m\n",
      "--------\n",
      "input:\n",
      "2961\n",
      "output:\n",
      "\u001b[31m7123\u001b[0m\n",
      "\u001b[31m4078\u001b[0m\n",
      "\u001b[31m6031\u001b[0m\n",
      "\u001b[31m5544\u001b[0m\n",
      "\u001b[31m3276\u001b[0m\n",
      "--------\n",
      "input:\n",
      "910\n",
      "output:\n",
      "\u001b[31m203\u001b[0m\n",
      "\u001b[31m249\u001b[0m\n",
      "\u001b[31m55\u001b[0m\n",
      "\u001b[31m3640\u001b[0m\n",
      "\u001b[31m8666\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7298\n",
      "output:\n",
      "\u001b[32m7298\u001b[0m\n",
      "\u001b[31m6894\u001b[0m\n",
      "\u001b[31m3123\u001b[0m\n",
      "\u001b[31m8308\u001b[0m\n",
      "\u001b[31m227\u001b[0m\n",
      "--------\n",
      "input:\n",
      "9260\n",
      "output:\n",
      "\u001b[31m9220\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "\u001b[31m6676\u001b[0m\n",
      "\u001b[31m10171\u001b[0m\n",
      "\u001b[31m6223\u001b[0m\n",
      "--------\n",
      "input:\n",
      "649\n",
      "output:\n",
      "\u001b[31m4125\u001b[0m\n",
      "\u001b[31m5670\u001b[0m\n",
      "\u001b[31m9107\u001b[0m\n",
      "\u001b[31m7765\u001b[0m\n",
      "\u001b[31m7765\u001b[0m\n",
      "--------\n",
      "input:\n",
      "2390\n",
      "output:\n",
      "\u001b[32m2390\u001b[0m\n",
      "\u001b[31m3668\u001b[0m\n",
      "\u001b[31m7385\u001b[0m\n",
      "\u001b[32m2390\u001b[0m\n",
      "\u001b[31m1055\u001b[0m\n",
      "--------\n",
      "input:\n",
      "1049\n",
      "output:\n",
      "\u001b[32m1049\u001b[0m\n",
      "\u001b[31m4841\u001b[0m\n",
      "\u001b[31m7229\u001b[0m\n",
      "\u001b[31m7734\u001b[0m\n",
      "\u001b[31m2392\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6392\n",
      "output:\n",
      "\u001b[31m7499\u001b[0m\n",
      "\u001b[31m4864\u001b[0m\n",
      "\u001b[32m6392\u001b[0m\n",
      "\u001b[31m4982\u001b[0m\n",
      "\u001b[31m3871\u001b[0m\n",
      "--------\n",
      "input:\n",
      "1055\n",
      "output:\n",
      "\u001b[31m2321\u001b[0m\n",
      "\u001b[31m2182\u001b[0m\n",
      "\u001b[31m5853\u001b[0m\n",
      "\u001b[31m8342\u001b[0m\n",
      "\u001b[31m2336\u001b[0m\n",
      "--------\n",
      "input:\n",
      "5703\n",
      "output:\n",
      "\u001b[32m5703\u001b[0m\n",
      "\u001b[31m1375\u001b[0m\n",
      "\u001b[32m5703\u001b[0m\n",
      "\u001b[31m3871\u001b[0m\n",
      "\u001b[31m3871\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7765\n",
      "output:\n",
      "\u001b[31m6307\u001b[0m\n",
      "\u001b[31m5670\u001b[0m\n",
      "\u001b[31m5544\u001b[0m\n",
      "\u001b[31m9262\u001b[0m\n",
      "\u001b[32m7765\u001b[0m\n",
      "--------\n",
      "input:\n",
      "269\n",
      "output:\n",
      "\u001b[31m7932\u001b[0m\n",
      "\u001b[31m3658\u001b[0m\n",
      "\u001b[31m6676\u001b[0m\n",
      "\u001b[31m7931\u001b[0m\n",
      "\u001b[31m9193\u001b[0m\n",
      "--------\n",
      "input:\n",
      "249\n",
      "output:\n",
      "\u001b[31m7123\u001b[0m\n",
      "\u001b[31m5327\u001b[0m\n",
      "\u001b[31m5310\u001b[0m\n",
      "\u001b[31m520\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "--------\n",
      "input:\n",
      "5703\n",
      "output:\n",
      "\u001b[32m5703\u001b[0m\n",
      "\u001b[32m5703\u001b[0m\n",
      "\u001b[32m5703\u001b[0m\n",
      "\u001b[31m8018\u001b[0m\n",
      "\u001b[31m4286\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7734\n",
      "output:\n",
      "\u001b[32m7734\u001b[0m\n",
      "\u001b[32m7734\u001b[0m\n",
      "\u001b[31m7385\u001b[0m\n",
      "\u001b[32m7734\u001b[0m\n",
      "\u001b[31m2321\u001b[0m\n",
      "--------\n",
      "input:\n",
      "4090\n",
      "output:\n",
      "\u001b[31m8282\u001b[0m\n",
      "\u001b[31m8308\u001b[0m\n",
      "\u001b[31m3725\u001b[0m\n",
      "\u001b[31m3249\u001b[0m\n",
      "\u001b[31m4074\u001b[0m\n",
      "--------\n",
      "input:\n",
      "379\n",
      "output:\n",
      "\u001b[31m249\u001b[0m\n",
      "\u001b[31m2135\u001b[0m\n",
      "\u001b[31m3780\u001b[0m\n",
      "\u001b[31m2135\u001b[0m\n",
      "\u001b[31m5310\u001b[0m\n",
      "--------\n",
      "input:\n",
      "5853\n",
      "output:\n",
      "\u001b[31m6894\u001b[0m\n",
      "\u001b[31m7429\u001b[0m\n",
      "\u001b[31m7385\u001b[0m\n",
      "\u001b[31m487\u001b[0m\n",
      "\u001b[31m6404\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6009\n",
      "output:\n",
      "\u001b[31m6894\u001b[0m\n",
      "\u001b[31m2570\u001b[0m\n",
      "\u001b[31m6404\u001b[0m\n",
      "\u001b[31m6883\u001b[0m\n",
      "\u001b[31m8865\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3784\n",
      "output:\n",
      "\u001b[32m3784\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "\u001b[31m890\u001b[0m\n",
      "\u001b[31m1785\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "--------\n",
      "input:\n",
      "8078\n",
      "output:\n",
      "\u001b[31m5078\u001b[0m\n",
      "\u001b[31m7734\u001b[0m\n",
      "\u001b[31m4074\u001b[0m\n",
      "\u001b[31m6480\u001b[0m\n",
      "\u001b[31m10005\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3276\n",
      "output:\n",
      "\u001b[31m203\u001b[0m\n",
      "\u001b[31m7488\u001b[0m\n",
      "\u001b[31m5310\u001b[0m\n",
      "\u001b[31m9193\u001b[0m\n",
      "\u001b[31m8986\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7009\n",
      "output:\n",
      "\u001b[31m3561\u001b[0m\n",
      "\u001b[31m258\u001b[0m\n",
      "\u001b[31m4982\u001b[0m\n",
      "\u001b[32m7009\u001b[0m\n",
      "\u001b[31m10171\u001b[0m\n",
      "--------\n",
      "input:\n",
      "8425\n",
      "output:\n",
      "\u001b[31m4286\u001b[0m\n",
      "\u001b[31m4286\u001b[0m\n",
      "\u001b[31m520\u001b[0m\n",
      "\u001b[31m7777\u001b[0m\n",
      "\u001b[31m5703\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3226\n",
      "output:\n",
      "\u001b[31m2570\u001b[0m\n",
      "\u001b[31m7009\u001b[0m\n",
      "\u001b[31m4286\u001b[0m\n",
      "\u001b[31m7777\u001b[0m\n",
      "\u001b[31m5703\u001b[0m\n",
      "--------\n",
      "input:\n",
      "4864\n",
      "output:\n",
      "\u001b[31m487\u001b[0m\n",
      "\u001b[31m6031\u001b[0m\n",
      "\u001b[31m4078\u001b[0m\n",
      "\u001b[31m5327\u001b[0m\n",
      "\u001b[31m8425\u001b[0m\n",
      "--------\n",
      "input:\n",
      "2754\n",
      "output:\n",
      "\u001b[31m1896\u001b[0m\n",
      "\u001b[31m6480\u001b[0m\n",
      "\u001b[31m8666\u001b[0m\n",
      "\u001b[31m5081\u001b[0m\n",
      "\u001b[31m4841\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7814\n",
      "output:\n",
      "\u001b[31m2337\u001b[0m\n",
      "\u001b[31m7932\u001b[0m\n",
      "\u001b[31m6676\u001b[0m\n",
      "\u001b[31m193\u001b[0m\n",
      "\u001b[31m8282\u001b[0m\n",
      "--------\n",
      "input:\n",
      "9586\n",
      "output:\n",
      "\u001b[31m6894\u001b[0m\n",
      "\u001b[31m9546\u001b[0m\n",
      "\u001b[31m1318\u001b[0m\n",
      "\u001b[31m5081\u001b[0m\n",
      "\u001b[31m4403\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6009\n",
      "output:\n",
      "\u001b[31m55\u001b[0m\n",
      "\u001b[31m946\u001b[0m\n",
      "\u001b[31m1878\u001b[0m\n",
      "\u001b[31m8865\u001b[0m\n",
      "\u001b[31m31\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7971\n",
      "output:\n",
      "\u001b[31m5544\u001b[0m\n",
      "\u001b[31m6325\u001b[0m\n",
      "\u001b[31m3871\u001b[0m\n",
      "\u001b[31m1785\u001b[0m\n",
      "\u001b[31m4286\u001b[0m\n",
      "--------\n",
      "input:\n",
      "2391\n",
      "output:\n",
      "\u001b[32m2391\u001b[0m\n",
      "\u001b[31m7229\u001b[0m\n",
      "\u001b[31m2336\u001b[0m\n",
      "\u001b[31m4403\u001b[0m\n",
      "\u001b[31m7229\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6865\n",
      "output:\n",
      "\u001b[32m6865\u001b[0m\n",
      "\u001b[31m6730\u001b[0m\n",
      "\u001b[32m6865\u001b[0m\n",
      "\u001b[31m5081\u001b[0m\n",
      "\u001b[31m3587\u001b[0m\n",
      "--------\n",
      "input:\n",
      "9193\n",
      "output:\n",
      "\u001b[31m946\u001b[0m\n",
      "\u001b[31m2336\u001b[0m\n",
      "\u001b[32m9193\u001b[0m\n",
      "\u001b[31m946\u001b[0m\n",
      "\u001b[32m9193\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3836\n",
      "output:\n",
      "\u001b[32m3836\u001b[0m\n",
      "\u001b[31m5382\u001b[0m\n",
      "\u001b[31m4403\u001b[0m\n",
      "\u001b[31m3668\u001b[0m\n",
      "\u001b[31m1049\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7081\n",
      "output:\n",
      "\u001b[31m6325\u001b[0m\n",
      "\u001b[31m2533\u001b[0m\n",
      "\u001b[31m7932\u001b[0m\n",
      "\u001b[31m6325\u001b[0m\n",
      "\u001b[31m6325\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6031\n",
      "output:\n",
      "\u001b[31m4078\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "\u001b[31m890\u001b[0m\n",
      "\u001b[31m3780\u001b[0m\n",
      "\u001b[31m2907\u001b[0m\n",
      "--------\n",
      "input:\n",
      "4469\n",
      "output:\n",
      "\u001b[31m1318\u001b[0m\n",
      "\u001b[31m3099\u001b[0m\n",
      "\u001b[31m258\u001b[0m\n",
      "\u001b[32m4469\u001b[0m\n",
      "\u001b[31m6676\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7429\n",
      "output:\n",
      "\u001b[31m3871\u001b[0m\n",
      "\u001b[31m6031\u001b[0m\n",
      "\u001b[32m7429\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "\u001b[31m249\u001b[0m\n",
      "--------\n",
      "input:\n",
      "10005\n",
      "output:\n",
      "\u001b[32m10005\u001b[0m\n",
      "\u001b[31m5081\u001b[0m\n",
      "\u001b[31m7472\u001b[0m\n",
      "\u001b[31m7229\u001b[0m\n",
      "\u001b[32m10005\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7499\n",
      "output:\n",
      "\u001b[31m837\u001b[0m\n",
      "\u001b[31m7777\u001b[0m\n",
      "\u001b[31m5703\u001b[0m\n",
      "\u001b[31m8425\u001b[0m\n",
      "\u001b[31m4864\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6325\n",
      "output:\n",
      "\u001b[32m6325\u001b[0m\n",
      "\u001b[32m6325\u001b[0m\n",
      "\u001b[32m6325\u001b[0m\n",
      "\u001b[32m6325\u001b[0m\n",
      "\u001b[31m4286\u001b[0m\n",
      "--------\n",
      "input:\n",
      "4438\n",
      "output:\n",
      "\u001b[31m790\u001b[0m\n",
      "\u001b[31m8018\u001b[0m\n",
      "\u001b[32m4438\u001b[0m\n",
      "\u001b[31m3428\u001b[0m\n",
      "\u001b[31m3428\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3226\n",
      "output:\n",
      "\u001b[32m3226\u001b[0m\n",
      "\u001b[31m249\u001b[0m\n",
      "\u001b[31m3871\u001b[0m\n",
      "\u001b[31m3464\u001b[0m\n",
      "\u001b[31m3780\u001b[0m\n",
      "--------\n",
      "input:\n",
      "9220\n",
      "output:\n",
      "\u001b[31m7971\u001b[0m\n",
      "\u001b[31m5912\u001b[0m\n",
      "\u001b[31m1558\u001b[0m\n",
      "\u001b[31m487\u001b[0m\n",
      "\u001b[31m5703\u001b[0m\n",
      "--------\n",
      "input:\n",
      "2392\n",
      "output:\n",
      "\u001b[31m3836\u001b[0m\n",
      "\u001b[31m7118\u001b[0m\n",
      "\u001b[31m3830\u001b[0m\n",
      "\u001b[31m6730\u001b[0m\n",
      "\u001b[32m2392\u001b[0m\n",
      "--------\n",
      "input:\n",
      "8506\n",
      "output:\n",
      "\u001b[31m9107\u001b[0m\n",
      "\u001b[31m7499\u001b[0m\n",
      "\u001b[31m9107\u001b[0m\n",
      "\u001b[31m9107\u001b[0m\n",
      "\u001b[31m4286\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6515\n",
      "output:\n",
      "\u001b[31m10171\u001b[0m\n",
      "\u001b[31m9260\u001b[0m\n",
      "\u001b[31m5081\u001b[0m\n",
      "\u001b[31m227\u001b[0m\n",
      "\u001b[31m7385\u001b[0m\n",
      "--------\n",
      "input:\n",
      "2999\n",
      "output:\n",
      "\u001b[32m2999\u001b[0m\n",
      "\u001b[31m3604\u001b[0m\n",
      "\u001b[31m4841\u001b[0m\n",
      "\u001b[31m1896\u001b[0m\n",
      "\u001b[31m1055\u001b[0m\n",
      "--------\n",
      "input:\n",
      "5055\n",
      "output:\n",
      "\u001b[31m3099\u001b[0m\n",
      "\u001b[31m7765\u001b[0m\n",
      "\u001b[31m6307\u001b[0m\n",
      "\u001b[31m6157\u001b[0m\n",
      "\u001b[31m7765\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7309\n",
      "output:\n",
      "\u001b[32m7309\u001b[0m\n",
      "\u001b[31m487\u001b[0m\n",
      "\u001b[32m7309\u001b[0m\n",
      "\u001b[31m5327\u001b[0m\n",
      "\u001b[31m4078\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7009\n",
      "output:\n",
      "\u001b[31m203\u001b[0m\n",
      "\u001b[31m6031\u001b[0m\n",
      "\u001b[31m8018\u001b[0m\n",
      "\u001b[32m7009\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3099\n",
      "output:\n",
      "\u001b[32m3099\u001b[0m\n",
      "\u001b[31m1363\u001b[0m\n",
      "\u001b[31m8425\u001b[0m\n",
      "\u001b[31m6515\u001b[0m\n",
      "\u001b[32m3099\u001b[0m\n",
      "--------\n",
      "input:\n",
      "5703\n",
      "output:\n",
      "\u001b[31m4286\u001b[0m\n",
      "\u001b[32m5703\u001b[0m\n",
      "\u001b[32m5703\u001b[0m\n",
      "\u001b[31m4286\u001b[0m\n",
      "\u001b[31m6325\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3762\n",
      "output:\n",
      "\u001b[31m10171\u001b[0m\n",
      "\u001b[31m4078\u001b[0m\n",
      "\u001b[31m5327\u001b[0m\n",
      "\u001b[31m3871\u001b[0m\n",
      "\u001b[31m3099\u001b[0m\n",
      "--------\n",
      "input:\n",
      "5440\n",
      "output:\n",
      "\u001b[31m4286\u001b[0m\n",
      "\u001b[31m4286\u001b[0m\n",
      "\u001b[31m6325\u001b[0m\n",
      "\u001b[31m3780\u001b[0m\n",
      "\u001b[31m487\u001b[0m\n",
      "--------\n",
      "input:\n",
      "4125\n",
      "output:\n",
      "\u001b[31m5327\u001b[0m\n",
      "\u001b[31m3464\u001b[0m\n",
      "\u001b[31m1785\u001b[0m\n",
      "\u001b[31m1375\u001b[0m\n",
      "\u001b[31m7132\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3762\n",
      "output:\n",
      "\u001b[31m9701\u001b[0m\n",
      "\u001b[32m3762\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "\u001b[31m563\u001b[0m\n",
      "\u001b[31m7932\u001b[0m\n",
      "--------\n",
      "input:\n",
      "649\n",
      "output:\n",
      "\u001b[31m9220\u001b[0m\n",
      "\u001b[31m4982\u001b[0m\n",
      "\u001b[31m3871\u001b[0m\n",
      "\u001b[31m5703\u001b[0m\n",
      "\u001b[31m6031\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7298\n",
      "output:\n",
      "\u001b[31m9285\u001b[0m\n",
      "\u001b[31m3762\u001b[0m\n",
      "\u001b[31m9262\u001b[0m\n",
      "\u001b[32m7298\u001b[0m\n",
      "\u001b[31m8505\u001b[0m\n",
      "--------\n",
      "input:\n",
      "9260\n",
      "output:\n",
      "\u001b[31m3762\u001b[0m\n",
      "\u001b[31m3276\u001b[0m\n",
      "\u001b[31m7298\u001b[0m\n",
      "\u001b[31m4078\u001b[0m\n",
      "\u001b[31m9220\u001b[0m\n",
      "--------\n",
      "input:\n",
      "2999\n",
      "output:\n",
      "\u001b[31m7710\u001b[0m\n",
      "\u001b[31m7229\u001b[0m\n",
      "\u001b[31m2533\u001b[0m\n",
      "\u001b[31m5382\u001b[0m\n",
      "\u001b[31m10005\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3428\n",
      "output:\n",
      "\u001b[31m487\u001b[0m\n",
      "\u001b[31m1558\u001b[0m\n",
      "\u001b[31m5081\u001b[0m\n",
      "\u001b[31m4518\u001b[0m\n",
      "\u001b[31m4818\u001b[0m\n",
      "--------\n",
      "input:\n",
      "8865\n",
      "output:\n",
      "\u001b[31m2390\u001b[0m\n",
      "\u001b[32m8865\u001b[0m\n",
      "\u001b[31m4700\u001b[0m\n",
      "\u001b[31m4700\u001b[0m\n",
      "\u001b[31m3249\u001b[0m\n",
      "--------\n",
      "input:\n",
      "9724\n",
      "output:\n",
      "\u001b[31m7932\u001b[0m\n",
      "\u001b[31m5670\u001b[0m\n",
      "\u001b[31m7385\u001b[0m\n",
      "\u001b[31m5670\u001b[0m\n",
      "\u001b[31m5081\u001b[0m\n",
      "--------\n",
      "input:\n",
      "837\n",
      "output:\n",
      "\u001b[31m7499\u001b[0m\n",
      "\u001b[32m837\u001b[0m\n",
      "\u001b[31m7710\u001b[0m\n",
      "\u001b[31m7385\u001b[0m\n",
      "\u001b[31m2141\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6883\n",
      "output:\n",
      "\u001b[32m6883\u001b[0m\n",
      "\u001b[31m4308\u001b[0m\n",
      "\u001b[31m4308\u001b[0m\n",
      "\u001b[31m4308\u001b[0m\n",
      "\u001b[31m2168\u001b[0m\n",
      "--------\n",
      "input:\n",
      "5912\n",
      "output:\n",
      "\u001b[31m7429\u001b[0m\n",
      "\u001b[31m7429\u001b[0m\n",
      "\u001b[31m2896\u001b[0m\n",
      "\u001b[32m5912\u001b[0m\n",
      "\u001b[31m3871\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7123\n",
      "output:\n",
      "\u001b[31m5544\u001b[0m\n",
      "\u001b[32m7123\u001b[0m\n",
      "\u001b[32m7123\u001b[0m\n",
      "\u001b[31m249\u001b[0m\n",
      "\u001b[31m1785\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6511\n",
      "output:\n",
      "\u001b[31m4078\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "\u001b[31m6031\u001b[0m\n",
      "\u001b[31m10171\u001b[0m\n",
      "\u001b[31m1318\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7777\n",
      "output:\n",
      "\u001b[31m6617\u001b[0m\n",
      "\u001b[31m2533\u001b[0m\n",
      "\u001b[31m2849\u001b[0m\n",
      "\u001b[31m7229\u001b[0m\n",
      "\u001b[31m9260\u001b[0m\n",
      "--------\n",
      "input:\n",
      "5853\n",
      "output:\n",
      "\u001b[31m6676\u001b[0m\n",
      "\u001b[32m5853\u001b[0m\n",
      "\u001b[31m7932\u001b[0m\n",
      "\u001b[31m3428\u001b[0m\n",
      "\u001b[31m3428\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7429\n",
      "output:\n",
      "\u001b[31m3871\u001b[0m\n",
      "\u001b[32m7429\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "\u001b[31m487\u001b[0m\n",
      "\u001b[31m6031\u001b[0m\n",
      "--------\n",
      "input:\n",
      "3762\n",
      "output:\n",
      "\u001b[31m6325\u001b[0m\n",
      "\u001b[31m3871\u001b[0m\n",
      "\u001b[31m487\u001b[0m\n",
      "\u001b[31m4078\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "--------\n",
      "input:\n",
      "4841\n",
      "output:\n",
      "\u001b[32m4841\u001b[0m\n",
      "\u001b[31m3249\u001b[0m\n",
      "\u001b[31m7229\u001b[0m\n",
      "\u001b[31m5081\u001b[0m\n",
      "\u001b[31m4403\u001b[0m\n",
      "--------\n",
      "input:\n",
      "7385\n",
      "output:\n",
      "\u001b[31m3640\u001b[0m\n",
      "\u001b[31m914\u001b[0m\n",
      "\u001b[31m2390\u001b[0m\n",
      "\u001b[31m227\u001b[0m\n",
      "\u001b[31m790\u001b[0m\n",
      "--------\n",
      "input:\n",
      "1375\n",
      "output:\n",
      "\u001b[31m7123\u001b[0m\n",
      "\u001b[31m3871\u001b[0m\n",
      "\u001b[31m3871\u001b[0m\n",
      "\u001b[31m5703\u001b[0m\n",
      "\u001b[31m4286\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6009\n",
      "output:\n",
      "\u001b[31m132\u001b[0m\n",
      "\u001b[31m5078\u001b[0m\n",
      "\u001b[31m3668\u001b[0m\n",
      "\u001b[31m8282\u001b[0m\n",
      "\u001b[31m2390\u001b[0m\n",
      "--------\n",
      "input:\n",
      "2260\n",
      "output:\n",
      "\u001b[31m8425\u001b[0m\n",
      "\u001b[31m7765\u001b[0m\n",
      "\u001b[31m2961\u001b[0m\n",
      "\u001b[31m7488\u001b[0m\n",
      "\u001b[31m4286\u001b[0m\n",
      "--------\n",
      "input:\n",
      "193\n",
      "output:\n",
      "\u001b[31m914\u001b[0m\n",
      "\u001b[31m227\u001b[0m\n",
      "\u001b[31m5081\u001b[0m\n",
      "\u001b[31m4308\u001b[0m\n",
      "\u001b[32m193\u001b[0m\n",
      "--------\n",
      "input:\n",
      "132\n",
      "output:\n",
      "\u001b[32m132\u001b[0m\n",
      "\u001b[31m3604\u001b[0m\n",
      "\u001b[32m132\u001b[0m\n",
      "\u001b[31m3604\u001b[0m\n",
      "\u001b[31m6009\u001b[0m\n",
      "--------\n",
      "input:\n",
      "5853\n",
      "output:\n",
      "\u001b[31m8342\u001b[0m\n",
      "\u001b[31m8308\u001b[0m\n",
      "\u001b[32m5853\u001b[0m\n",
      "\u001b[32m5853\u001b[0m\n",
      "\u001b[31m3428\u001b[0m\n",
      "--------\n",
      "input:\n",
      "4308\n",
      "output:\n",
      "\u001b[31m914\u001b[0m\n",
      "\u001b[31m2999\u001b[0m\n",
      "\u001b[31m2392\u001b[0m\n",
      "\u001b[32m4308\u001b[0m\n",
      "\u001b[31m5081\u001b[0m\n",
      "--------\n",
      "input:\n",
      "5055\n",
      "output:\n",
      "\u001b[32m5055\u001b[0m\n",
      "\u001b[31m3099\u001b[0m\n",
      "\u001b[31m2849\u001b[0m\n",
      "\u001b[31m3762\u001b[0m\n",
      "\u001b[31m7429\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6071\n",
      "output:\n",
      "\u001b[31m7229\u001b[0m\n",
      "\u001b[31m3668\u001b[0m\n",
      "\u001b[32m6071\u001b[0m\n",
      "\u001b[32m6071\u001b[0m\n",
      "\u001b[31m269\u001b[0m\n",
      "--------\n",
      "input:\n",
      "31\n",
      "output:\n",
      "\u001b[31m7385\u001b[0m\n",
      "\u001b[31m946\u001b[0m\n",
      "\u001b[31m2336\u001b[0m\n",
      "\u001b[31m7472\u001b[0m\n",
      "\u001b[31m2336\u001b[0m\n",
      "--------\n",
      "input:\n",
      "6676\n",
      "output:\n",
      "\u001b[32m6676\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "\u001b[31m563\u001b[0m\n",
      "\u001b[31m4078\u001b[0m\n",
      "\u001b[31m7123\u001b[0m\n",
      "--------\n",
      "input:\n",
      "2907\n",
      "output:\n",
      "\u001b[32m2907\u001b[0m\n",
      "\u001b[32m2907\u001b[0m\n",
      "\u001b[31m520\u001b[0m\n",
      "\u001b[31m5912\u001b[0m\n",
      "\u001b[31m8425\u001b[0m\n",
      "--------\n",
      "Count Of True: 74\n",
      "Count Of False: 426\n",
      "Count Of All: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>input</td><td>output1</td><td>output2</td><td>output3</td><td>output4</td><td>output5</td></tr>\n",
       "<tr><td>4818 </td><td>9586   </td><td>3830   </td><td>9641   </td><td>6626   </td><td>193    </td></tr>\n",
       "<tr><td>227  </td><td>193    </td><td>1878   </td><td>193    </td><td>8865   </td><td>3784   </td></tr>\n",
       "<tr><td>3658 </td><td>2168   </td><td>9546   </td><td>7932   </td><td>9586   </td><td>7453   </td></tr>\n",
       "<tr><td>6480 </td><td>3668   </td><td>3668   </td><td>2346   </td><td>7229   </td><td>6480   </td></tr>\n",
       "<tr><td>9701 </td><td>5703   </td><td>249    </td><td>3780   </td><td>4469   </td><td>5703   </td></tr>\n",
       "<tr><td>7118 </td><td>1558   </td><td>132    </td><td>2321   </td><td>6617   </td><td>7299   </td></tr>\n",
       "<tr><td>3784 </td><td>3784   </td><td>3784   </td><td>2896   </td><td>2896   </td><td>3784   </td></tr>\n",
       "<tr><td>3226 </td><td>5544   </td><td>6031   </td><td>7665   </td><td>3871   </td><td>5703   </td></tr>\n",
       "<tr><td>6515 </td><td>1785   </td><td>3464   </td><td>3464   </td><td>1375   </td><td>1375   </td></tr>\n",
       "<tr><td>4069 </td><td>227    </td><td>2999   </td><td>7932   </td><td>2570   </td><td>7499   </td></tr>\n",
       "<tr><td>5703 </td><td>5703   </td><td>5703   </td><td>5327   </td><td>5703   </td><td>5703   </td></tr>\n",
       "<tr><td>4518 </td><td>2390   </td><td>2390   </td><td>4518   </td><td>3668   </td><td>4518   </td></tr>\n",
       "<tr><td>2961 </td><td>7123   </td><td>4078   </td><td>6031   </td><td>5544   </td><td>3276   </td></tr>\n",
       "<tr><td>910  </td><td>203    </td><td>249    </td><td>55     </td><td>3640   </td><td>8666   </td></tr>\n",
       "<tr><td>7298 </td><td>7298   </td><td>6894   </td><td>3123   </td><td>8308   </td><td>227    </td></tr>\n",
       "<tr><td>9260 </td><td>9220   </td><td>7123   </td><td>6676   </td><td>10171  </td><td>6223   </td></tr>\n",
       "<tr><td>649  </td><td>4125   </td><td>5670   </td><td>9107   </td><td>7765   </td><td>7765   </td></tr>\n",
       "<tr><td>2390 </td><td>2390   </td><td>3668   </td><td>7385   </td><td>2390   </td><td>1055   </td></tr>\n",
       "<tr><td>1049 </td><td>1049   </td><td>4841   </td><td>7229   </td><td>7734   </td><td>2392   </td></tr>\n",
       "<tr><td>6392 </td><td>7499   </td><td>4864   </td><td>6392   </td><td>4982   </td><td>3871   </td></tr>\n",
       "<tr><td>1055 </td><td>2321   </td><td>2182   </td><td>5853   </td><td>8342   </td><td>2336   </td></tr>\n",
       "<tr><td>5703 </td><td>5703   </td><td>1375   </td><td>5703   </td><td>3871   </td><td>3871   </td></tr>\n",
       "<tr><td>7765 </td><td>6307   </td><td>5670   </td><td>5544   </td><td>9262   </td><td>7765   </td></tr>\n",
       "<tr><td>269  </td><td>7932   </td><td>3658   </td><td>6676   </td><td>7931   </td><td>9193   </td></tr>\n",
       "<tr><td>249  </td><td>7123   </td><td>5327   </td><td>5310   </td><td>520    </td><td>7123   </td></tr>\n",
       "<tr><td>5703 </td><td>5703   </td><td>5703   </td><td>5703   </td><td>8018   </td><td>4286   </td></tr>\n",
       "<tr><td>7734 </td><td>7734   </td><td>7734   </td><td>7385   </td><td>7734   </td><td>2321   </td></tr>\n",
       "<tr><td>4090 </td><td>8282   </td><td>8308   </td><td>3725   </td><td>3249   </td><td>4074   </td></tr>\n",
       "<tr><td>379  </td><td>249    </td><td>2135   </td><td>3780   </td><td>2135   </td><td>5310   </td></tr>\n",
       "<tr><td>5853 </td><td>6894   </td><td>7429   </td><td>7385   </td><td>487    </td><td>6404   </td></tr>\n",
       "<tr><td>6009 </td><td>6894   </td><td>2570   </td><td>6404   </td><td>6883   </td><td>8865   </td></tr>\n",
       "<tr><td>3784 </td><td>3784   </td><td>7123   </td><td>890    </td><td>1785   </td><td>7123   </td></tr>\n",
       "<tr><td>8078 </td><td>5078   </td><td>7734   </td><td>4074   </td><td>6480   </td><td>10005  </td></tr>\n",
       "<tr><td>3276 </td><td>203    </td><td>7488   </td><td>5310   </td><td>9193   </td><td>8986   </td></tr>\n",
       "<tr><td>7009 </td><td>3561   </td><td>258    </td><td>4982   </td><td>7009   </td><td>10171  </td></tr>\n",
       "<tr><td>8425 </td><td>4286   </td><td>4286   </td><td>520    </td><td>7777   </td><td>5703   </td></tr>\n",
       "<tr><td>3226 </td><td>2570   </td><td>7009   </td><td>4286   </td><td>7777   </td><td>5703   </td></tr>\n",
       "<tr><td>4864 </td><td>487    </td><td>6031   </td><td>4078   </td><td>5327   </td><td>8425   </td></tr>\n",
       "<tr><td>2754 </td><td>1896   </td><td>6480   </td><td>8666   </td><td>5081   </td><td>4841   </td></tr>\n",
       "<tr><td>7814 </td><td>2337   </td><td>7932   </td><td>6676   </td><td>193    </td><td>8282   </td></tr>\n",
       "<tr><td>9586 </td><td>6894   </td><td>9546   </td><td>1318   </td><td>5081   </td><td>4403   </td></tr>\n",
       "<tr><td>6009 </td><td>55     </td><td>946    </td><td>1878   </td><td>8865   </td><td>31     </td></tr>\n",
       "<tr><td>7971 </td><td>5544   </td><td>6325   </td><td>3871   </td><td>1785   </td><td>4286   </td></tr>\n",
       "<tr><td>2391 </td><td>2391   </td><td>7229   </td><td>2336   </td><td>4403   </td><td>7229   </td></tr>\n",
       "<tr><td>6865 </td><td>6865   </td><td>6730   </td><td>6865   </td><td>5081   </td><td>3587   </td></tr>\n",
       "<tr><td>9193 </td><td>946    </td><td>2336   </td><td>9193   </td><td>946    </td><td>9193   </td></tr>\n",
       "<tr><td>3836 </td><td>3836   </td><td>5382   </td><td>4403   </td><td>3668   </td><td>1049   </td></tr>\n",
       "<tr><td>7081 </td><td>6325   </td><td>2533   </td><td>7932   </td><td>6325   </td><td>6325   </td></tr>\n",
       "<tr><td>6031 </td><td>4078   </td><td>7123   </td><td>890    </td><td>3780   </td><td>2907   </td></tr>\n",
       "<tr><td>4469 </td><td>1318   </td><td>3099   </td><td>258    </td><td>4469   </td><td>6676   </td></tr>\n",
       "<tr><td>7429 </td><td>3871   </td><td>6031   </td><td>7429   </td><td>7123   </td><td>249    </td></tr>\n",
       "<tr><td>10005</td><td>10005  </td><td>5081   </td><td>7472   </td><td>7229   </td><td>10005  </td></tr>\n",
       "<tr><td>7499 </td><td>837    </td><td>7777   </td><td>5703   </td><td>8425   </td><td>4864   </td></tr>\n",
       "<tr><td>6325 </td><td>6325   </td><td>6325   </td><td>6325   </td><td>6325   </td><td>4286   </td></tr>\n",
       "<tr><td>4438 </td><td>790    </td><td>8018   </td><td>4438   </td><td>3428   </td><td>3428   </td></tr>\n",
       "<tr><td>3226 </td><td>3226   </td><td>249    </td><td>3871   </td><td>3464   </td><td>3780   </td></tr>\n",
       "<tr><td>9220 </td><td>7971   </td><td>5912   </td><td>1558   </td><td>487    </td><td>5703   </td></tr>\n",
       "<tr><td>2392 </td><td>3836   </td><td>7118   </td><td>3830   </td><td>6730   </td><td>2392   </td></tr>\n",
       "<tr><td>8506 </td><td>9107   </td><td>7499   </td><td>9107   </td><td>9107   </td><td>4286   </td></tr>\n",
       "<tr><td>6515 </td><td>10171  </td><td>9260   </td><td>5081   </td><td>227    </td><td>7385   </td></tr>\n",
       "<tr><td>2999 </td><td>2999   </td><td>3604   </td><td>4841   </td><td>1896   </td><td>1055   </td></tr>\n",
       "<tr><td>5055 </td><td>3099   </td><td>7765   </td><td>6307   </td><td>6157   </td><td>7765   </td></tr>\n",
       "<tr><td>7309 </td><td>7309   </td><td>487    </td><td>7309   </td><td>5327   </td><td>4078   </td></tr>\n",
       "<tr><td>7009 </td><td>203    </td><td>6031   </td><td>8018   </td><td>7009   </td><td>7123   </td></tr>\n",
       "<tr><td>3099 </td><td>3099   </td><td>1363   </td><td>8425   </td><td>6515   </td><td>3099   </td></tr>\n",
       "<tr><td>5703 </td><td>4286   </td><td>5703   </td><td>5703   </td><td>4286   </td><td>6325   </td></tr>\n",
       "<tr><td>3762 </td><td>10171  </td><td>4078   </td><td>5327   </td><td>3871   </td><td>3099   </td></tr>\n",
       "<tr><td>5440 </td><td>4286   </td><td>4286   </td><td>6325   </td><td>3780   </td><td>487    </td></tr>\n",
       "<tr><td>4125 </td><td>5327   </td><td>3464   </td><td>1785   </td><td>1375   </td><td>7132   </td></tr>\n",
       "<tr><td>3762 </td><td>9701   </td><td>3762   </td><td>7123   </td><td>563    </td><td>7932   </td></tr>\n",
       "<tr><td>649  </td><td>9220   </td><td>4982   </td><td>3871   </td><td>5703   </td><td>6031   </td></tr>\n",
       "<tr><td>7298 </td><td>9285   </td><td>3762   </td><td>9262   </td><td>7298   </td><td>8505   </td></tr>\n",
       "<tr><td>9260 </td><td>3762   </td><td>3276   </td><td>7298   </td><td>4078   </td><td>9220   </td></tr>\n",
       "<tr><td>2999 </td><td>7710   </td><td>7229   </td><td>2533   </td><td>5382   </td><td>10005  </td></tr>\n",
       "<tr><td>3428 </td><td>487    </td><td>1558   </td><td>5081   </td><td>4518   </td><td>4818   </td></tr>\n",
       "<tr><td>8865 </td><td>2390   </td><td>8865   </td><td>4700   </td><td>4700   </td><td>3249   </td></tr>\n",
       "<tr><td>9724 </td><td>7932   </td><td>5670   </td><td>7385   </td><td>5670   </td><td>5081   </td></tr>\n",
       "<tr><td>837  </td><td>7499   </td><td>837    </td><td>7710   </td><td>7385   </td><td>2141   </td></tr>\n",
       "<tr><td>6883 </td><td>6883   </td><td>4308   </td><td>4308   </td><td>4308   </td><td>2168   </td></tr>\n",
       "<tr><td>5912 </td><td>7429   </td><td>7429   </td><td>2896   </td><td>5912   </td><td>3871   </td></tr>\n",
       "<tr><td>7123 </td><td>5544   </td><td>7123   </td><td>7123   </td><td>249    </td><td>1785   </td></tr>\n",
       "<tr><td>6511 </td><td>4078   </td><td>7123   </td><td>6031   </td><td>10171  </td><td>1318   </td></tr>\n",
       "<tr><td>7777 </td><td>6617   </td><td>2533   </td><td>2849   </td><td>7229   </td><td>9260   </td></tr>\n",
       "<tr><td>5853 </td><td>6676   </td><td>5853   </td><td>7932   </td><td>3428   </td><td>3428   </td></tr>\n",
       "<tr><td>7429 </td><td>3871   </td><td>7429   </td><td>7123   </td><td>487    </td><td>6031   </td></tr>\n",
       "<tr><td>3762 </td><td>6325   </td><td>3871   </td><td>487    </td><td>4078   </td><td>7123   </td></tr>\n",
       "<tr><td>4841 </td><td>4841   </td><td>3249   </td><td>7229   </td><td>5081   </td><td>4403   </td></tr>\n",
       "<tr><td>7385 </td><td>3640   </td><td>914    </td><td>2390   </td><td>227    </td><td>790    </td></tr>\n",
       "<tr><td>1375 </td><td>7123   </td><td>3871   </td><td>3871   </td><td>5703   </td><td>4286   </td></tr>\n",
       "<tr><td>6009 </td><td>132    </td><td>5078   </td><td>3668   </td><td>8282   </td><td>2390   </td></tr>\n",
       "<tr><td>2260 </td><td>8425   </td><td>7765   </td><td>2961   </td><td>7488   </td><td>4286   </td></tr>\n",
       "<tr><td>193  </td><td>914    </td><td>227    </td><td>5081   </td><td>4308   </td><td>193    </td></tr>\n",
       "<tr><td>132  </td><td>132    </td><td>3604   </td><td>132    </td><td>3604   </td><td>6009   </td></tr>\n",
       "<tr><td>5853 </td><td>8342   </td><td>8308   </td><td>5853   </td><td>5853   </td><td>3428   </td></tr>\n",
       "<tr><td>4308 </td><td>914    </td><td>2999   </td><td>2392   </td><td>4308   </td><td>5081   </td></tr>\n",
       "<tr><td>5055 </td><td>5055   </td><td>3099   </td><td>2849   </td><td>3762   </td><td>7429   </td></tr>\n",
       "<tr><td>6071 </td><td>7229   </td><td>3668   </td><td>6071   </td><td>6071   </td><td>269    </td></tr>\n",
       "<tr><td>31   </td><td>7385   </td><td>946    </td><td>2336   </td><td>7472   </td><td>2336   </td></tr>\n",
       "<tr><td>6676 </td><td>6676   </td><td>7123   </td><td>563    </td><td>4078   </td><td>7123   </td></tr>\n",
       "<tr><td>2907 </td><td>2907   </td><td>2907   </td><td>520    </td><td>5912   </td><td>8425   </td></tr>\n",
       "<tr><td>500  </td><td>0      </td><td>0      </td><td>0      </td><td>0      </td><td>74     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<tbody>\\n<tr><td>input</td><td>output1</td><td>output2</td><td>output3</td><td>output4</td><td>output5</td></tr>\\n<tr><td>4818 </td><td>9586   </td><td>3830   </td><td>9641   </td><td>6626   </td><td>193    </td></tr>\\n<tr><td>227  </td><td>193    </td><td>1878   </td><td>193    </td><td>8865   </td><td>3784   </td></tr>\\n<tr><td>3658 </td><td>2168   </td><td>9546   </td><td>7932   </td><td>9586   </td><td>7453   </td></tr>\\n<tr><td>6480 </td><td>3668   </td><td>3668   </td><td>2346   </td><td>7229   </td><td>6480   </td></tr>\\n<tr><td>9701 </td><td>5703   </td><td>249    </td><td>3780   </td><td>4469   </td><td>5703   </td></tr>\\n<tr><td>7118 </td><td>1558   </td><td>132    </td><td>2321   </td><td>6617   </td><td>7299   </td></tr>\\n<tr><td>3784 </td><td>3784   </td><td>3784   </td><td>2896   </td><td>2896   </td><td>3784   </td></tr>\\n<tr><td>3226 </td><td>5544   </td><td>6031   </td><td>7665   </td><td>3871   </td><td>5703   </td></tr>\\n<tr><td>6515 </td><td>1785   </td><td>3464   </td><td>3464   </td><td>1375   </td><td>1375   </td></tr>\\n<tr><td>4069 </td><td>227    </td><td>2999   </td><td>7932   </td><td>2570   </td><td>7499   </td></tr>\\n<tr><td>5703 </td><td>5703   </td><td>5703   </td><td>5327   </td><td>5703   </td><td>5703   </td></tr>\\n<tr><td>4518 </td><td>2390   </td><td>2390   </td><td>4518   </td><td>3668   </td><td>4518   </td></tr>\\n<tr><td>2961 </td><td>7123   </td><td>4078   </td><td>6031   </td><td>5544   </td><td>3276   </td></tr>\\n<tr><td>910  </td><td>203    </td><td>249    </td><td>55     </td><td>3640   </td><td>8666   </td></tr>\\n<tr><td>7298 </td><td>7298   </td><td>6894   </td><td>3123   </td><td>8308   </td><td>227    </td></tr>\\n<tr><td>9260 </td><td>9220   </td><td>7123   </td><td>6676   </td><td>10171  </td><td>6223   </td></tr>\\n<tr><td>649  </td><td>4125   </td><td>5670   </td><td>9107   </td><td>7765   </td><td>7765   </td></tr>\\n<tr><td>2390 </td><td>2390   </td><td>3668   </td><td>7385   </td><td>2390   </td><td>1055   </td></tr>\\n<tr><td>1049 </td><td>1049   </td><td>4841   </td><td>7229   </td><td>7734   </td><td>2392   </td></tr>\\n<tr><td>6392 </td><td>7499   </td><td>4864   </td><td>6392   </td><td>4982   </td><td>3871   </td></tr>\\n<tr><td>1055 </td><td>2321   </td><td>2182   </td><td>5853   </td><td>8342   </td><td>2336   </td></tr>\\n<tr><td>5703 </td><td>5703   </td><td>1375   </td><td>5703   </td><td>3871   </td><td>3871   </td></tr>\\n<tr><td>7765 </td><td>6307   </td><td>5670   </td><td>5544   </td><td>9262   </td><td>7765   </td></tr>\\n<tr><td>269  </td><td>7932   </td><td>3658   </td><td>6676   </td><td>7931   </td><td>9193   </td></tr>\\n<tr><td>249  </td><td>7123   </td><td>5327   </td><td>5310   </td><td>520    </td><td>7123   </td></tr>\\n<tr><td>5703 </td><td>5703   </td><td>5703   </td><td>5703   </td><td>8018   </td><td>4286   </td></tr>\\n<tr><td>7734 </td><td>7734   </td><td>7734   </td><td>7385   </td><td>7734   </td><td>2321   </td></tr>\\n<tr><td>4090 </td><td>8282   </td><td>8308   </td><td>3725   </td><td>3249   </td><td>4074   </td></tr>\\n<tr><td>379  </td><td>249    </td><td>2135   </td><td>3780   </td><td>2135   </td><td>5310   </td></tr>\\n<tr><td>5853 </td><td>6894   </td><td>7429   </td><td>7385   </td><td>487    </td><td>6404   </td></tr>\\n<tr><td>6009 </td><td>6894   </td><td>2570   </td><td>6404   </td><td>6883   </td><td>8865   </td></tr>\\n<tr><td>3784 </td><td>3784   </td><td>7123   </td><td>890    </td><td>1785   </td><td>7123   </td></tr>\\n<tr><td>8078 </td><td>5078   </td><td>7734   </td><td>4074   </td><td>6480   </td><td>10005  </td></tr>\\n<tr><td>3276 </td><td>203    </td><td>7488   </td><td>5310   </td><td>9193   </td><td>8986   </td></tr>\\n<tr><td>7009 </td><td>3561   </td><td>258    </td><td>4982   </td><td>7009   </td><td>10171  </td></tr>\\n<tr><td>8425 </td><td>4286   </td><td>4286   </td><td>520    </td><td>7777   </td><td>5703   </td></tr>\\n<tr><td>3226 </td><td>2570   </td><td>7009   </td><td>4286   </td><td>7777   </td><td>5703   </td></tr>\\n<tr><td>4864 </td><td>487    </td><td>6031   </td><td>4078   </td><td>5327   </td><td>8425   </td></tr>\\n<tr><td>2754 </td><td>1896   </td><td>6480   </td><td>8666   </td><td>5081   </td><td>4841   </td></tr>\\n<tr><td>7814 </td><td>2337   </td><td>7932   </td><td>6676   </td><td>193    </td><td>8282   </td></tr>\\n<tr><td>9586 </td><td>6894   </td><td>9546   </td><td>1318   </td><td>5081   </td><td>4403   </td></tr>\\n<tr><td>6009 </td><td>55     </td><td>946    </td><td>1878   </td><td>8865   </td><td>31     </td></tr>\\n<tr><td>7971 </td><td>5544   </td><td>6325   </td><td>3871   </td><td>1785   </td><td>4286   </td></tr>\\n<tr><td>2391 </td><td>2391   </td><td>7229   </td><td>2336   </td><td>4403   </td><td>7229   </td></tr>\\n<tr><td>6865 </td><td>6865   </td><td>6730   </td><td>6865   </td><td>5081   </td><td>3587   </td></tr>\\n<tr><td>9193 </td><td>946    </td><td>2336   </td><td>9193   </td><td>946    </td><td>9193   </td></tr>\\n<tr><td>3836 </td><td>3836   </td><td>5382   </td><td>4403   </td><td>3668   </td><td>1049   </td></tr>\\n<tr><td>7081 </td><td>6325   </td><td>2533   </td><td>7932   </td><td>6325   </td><td>6325   </td></tr>\\n<tr><td>6031 </td><td>4078   </td><td>7123   </td><td>890    </td><td>3780   </td><td>2907   </td></tr>\\n<tr><td>4469 </td><td>1318   </td><td>3099   </td><td>258    </td><td>4469   </td><td>6676   </td></tr>\\n<tr><td>7429 </td><td>3871   </td><td>6031   </td><td>7429   </td><td>7123   </td><td>249    </td></tr>\\n<tr><td>10005</td><td>10005  </td><td>5081   </td><td>7472   </td><td>7229   </td><td>10005  </td></tr>\\n<tr><td>7499 </td><td>837    </td><td>7777   </td><td>5703   </td><td>8425   </td><td>4864   </td></tr>\\n<tr><td>6325 </td><td>6325   </td><td>6325   </td><td>6325   </td><td>6325   </td><td>4286   </td></tr>\\n<tr><td>4438 </td><td>790    </td><td>8018   </td><td>4438   </td><td>3428   </td><td>3428   </td></tr>\\n<tr><td>3226 </td><td>3226   </td><td>249    </td><td>3871   </td><td>3464   </td><td>3780   </td></tr>\\n<tr><td>9220 </td><td>7971   </td><td>5912   </td><td>1558   </td><td>487    </td><td>5703   </td></tr>\\n<tr><td>2392 </td><td>3836   </td><td>7118   </td><td>3830   </td><td>6730   </td><td>2392   </td></tr>\\n<tr><td>8506 </td><td>9107   </td><td>7499   </td><td>9107   </td><td>9107   </td><td>4286   </td></tr>\\n<tr><td>6515 </td><td>10171  </td><td>9260   </td><td>5081   </td><td>227    </td><td>7385   </td></tr>\\n<tr><td>2999 </td><td>2999   </td><td>3604   </td><td>4841   </td><td>1896   </td><td>1055   </td></tr>\\n<tr><td>5055 </td><td>3099   </td><td>7765   </td><td>6307   </td><td>6157   </td><td>7765   </td></tr>\\n<tr><td>7309 </td><td>7309   </td><td>487    </td><td>7309   </td><td>5327   </td><td>4078   </td></tr>\\n<tr><td>7009 </td><td>203    </td><td>6031   </td><td>8018   </td><td>7009   </td><td>7123   </td></tr>\\n<tr><td>3099 </td><td>3099   </td><td>1363   </td><td>8425   </td><td>6515   </td><td>3099   </td></tr>\\n<tr><td>5703 </td><td>4286   </td><td>5703   </td><td>5703   </td><td>4286   </td><td>6325   </td></tr>\\n<tr><td>3762 </td><td>10171  </td><td>4078   </td><td>5327   </td><td>3871   </td><td>3099   </td></tr>\\n<tr><td>5440 </td><td>4286   </td><td>4286   </td><td>6325   </td><td>3780   </td><td>487    </td></tr>\\n<tr><td>4125 </td><td>5327   </td><td>3464   </td><td>1785   </td><td>1375   </td><td>7132   </td></tr>\\n<tr><td>3762 </td><td>9701   </td><td>3762   </td><td>7123   </td><td>563    </td><td>7932   </td></tr>\\n<tr><td>649  </td><td>9220   </td><td>4982   </td><td>3871   </td><td>5703   </td><td>6031   </td></tr>\\n<tr><td>7298 </td><td>9285   </td><td>3762   </td><td>9262   </td><td>7298   </td><td>8505   </td></tr>\\n<tr><td>9260 </td><td>3762   </td><td>3276   </td><td>7298   </td><td>4078   </td><td>9220   </td></tr>\\n<tr><td>2999 </td><td>7710   </td><td>7229   </td><td>2533   </td><td>5382   </td><td>10005  </td></tr>\\n<tr><td>3428 </td><td>487    </td><td>1558   </td><td>5081   </td><td>4518   </td><td>4818   </td></tr>\\n<tr><td>8865 </td><td>2390   </td><td>8865   </td><td>4700   </td><td>4700   </td><td>3249   </td></tr>\\n<tr><td>9724 </td><td>7932   </td><td>5670   </td><td>7385   </td><td>5670   </td><td>5081   </td></tr>\\n<tr><td>837  </td><td>7499   </td><td>837    </td><td>7710   </td><td>7385   </td><td>2141   </td></tr>\\n<tr><td>6883 </td><td>6883   </td><td>4308   </td><td>4308   </td><td>4308   </td><td>2168   </td></tr>\\n<tr><td>5912 </td><td>7429   </td><td>7429   </td><td>2896   </td><td>5912   </td><td>3871   </td></tr>\\n<tr><td>7123 </td><td>5544   </td><td>7123   </td><td>7123   </td><td>249    </td><td>1785   </td></tr>\\n<tr><td>6511 </td><td>4078   </td><td>7123   </td><td>6031   </td><td>10171  </td><td>1318   </td></tr>\\n<tr><td>7777 </td><td>6617   </td><td>2533   </td><td>2849   </td><td>7229   </td><td>9260   </td></tr>\\n<tr><td>5853 </td><td>6676   </td><td>5853   </td><td>7932   </td><td>3428   </td><td>3428   </td></tr>\\n<tr><td>7429 </td><td>3871   </td><td>7429   </td><td>7123   </td><td>487    </td><td>6031   </td></tr>\\n<tr><td>3762 </td><td>6325   </td><td>3871   </td><td>487    </td><td>4078   </td><td>7123   </td></tr>\\n<tr><td>4841 </td><td>4841   </td><td>3249   </td><td>7229   </td><td>5081   </td><td>4403   </td></tr>\\n<tr><td>7385 </td><td>3640   </td><td>914    </td><td>2390   </td><td>227    </td><td>790    </td></tr>\\n<tr><td>1375 </td><td>7123   </td><td>3871   </td><td>3871   </td><td>5703   </td><td>4286   </td></tr>\\n<tr><td>6009 </td><td>132    </td><td>5078   </td><td>3668   </td><td>8282   </td><td>2390   </td></tr>\\n<tr><td>2260 </td><td>8425   </td><td>7765   </td><td>2961   </td><td>7488   </td><td>4286   </td></tr>\\n<tr><td>193  </td><td>914    </td><td>227    </td><td>5081   </td><td>4308   </td><td>193    </td></tr>\\n<tr><td>132  </td><td>132    </td><td>3604   </td><td>132    </td><td>3604   </td><td>6009   </td></tr>\\n<tr><td>5853 </td><td>8342   </td><td>8308   </td><td>5853   </td><td>5853   </td><td>3428   </td></tr>\\n<tr><td>4308 </td><td>914    </td><td>2999   </td><td>2392   </td><td>4308   </td><td>5081   </td></tr>\\n<tr><td>5055 </td><td>5055   </td><td>3099   </td><td>2849   </td><td>3762   </td><td>7429   </td></tr>\\n<tr><td>6071 </td><td>7229   </td><td>3668   </td><td>6071   </td><td>6071   </td><td>269    </td></tr>\\n<tr><td>31   </td><td>7385   </td><td>946    </td><td>2336   </td><td>7472   </td><td>2336   </td></tr>\\n<tr><td>6676 </td><td>6676   </td><td>7123   </td><td>563    </td><td>4078   </td><td>7123   </td></tr>\\n<tr><td>2907 </td><td>2907   </td><td>2907   </td><td>520    </td><td>5912   </td><td>8425   </td></tr>\\n<tr><td>500  </td><td>0      </td><td>0      </td><td>0      </td><td>0      </td><td>74     </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_of_true=0\n",
    "count_of_false=0\n",
    "count_of_all=0\n",
    "\n",
    "AllData=[['input','output1','output2','output3','output4','output5']]\n",
    "for input in test: \n",
    "    index_of_test=img_names.index(input)\n",
    "    input_folder=img_folders[index_of_test] \n",
    "    thisrec=[input_folder] \n",
    "    print('input:')\n",
    "    print(input_folder)\n",
    "    # img = mpimg.imread(img_path_dogs[index_of_test].replace(' ',''))\n",
    "    # imgplot = plt.imshow(img)\n",
    "    # plt.show()\n",
    "    input_ssa=SSA_features[index_of_test]\n",
    "    score_of_trained=[]\n",
    "    for trained in training:\n",
    "        index_of_trained=img_names.index(trained)\n",
    "        trained_ssa=SSA_features[index_of_trained]\n",
    "        distance= sqrt( sum(np.multiply(trained_ssa - input_ssa,trained_ssa - input_ssa)))\n",
    "        trained_folder=img_folders[index_of_trained]\n",
    "        score_of_trained.append([distance,trained,trained_folder])\n",
    "    score_of_trained.sort()\n",
    "    score_of_trained=score_of_trained[:count_of_results] \n",
    "    count_of_this_true=0\n",
    "    print('output:')\n",
    "    for res in score_of_trained:  \n",
    "        if(res[2]==input_folder):\n",
    "            print(colored(res[2],'green'))\n",
    "            count_of_true=count_of_true+1\n",
    "        else:\n",
    "            print(colored(res[2],'red'))\n",
    "            count_of_false=count_of_false+1\n",
    "        \n",
    "        thisrec.append(res[2])\n",
    "        count_of_all=count_of_all+1 \n",
    "        # img=mpimg.imread(os.getcwd()+'/data-set/celeba/Clean/'+res[1])\n",
    "        # imgplot=plt.imshow(img)\n",
    "        # plt.show() \n",
    "    print('--------')\n",
    "    AllData.append(thisrec)    \n",
    "AllData.append([count_of_all,0,0,0,0,count_of_true])\n",
    "print('Count Of True: '+str(count_of_true))\n",
    "print('Count Of False: '+str(count_of_false))\n",
    "print('Count Of All: '+str(count_of_all))\n",
    "table = tabulate.tabulate(AllData, tablefmt='html')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saliency Part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/saliency/core/xrai.py:126: FutureWarning: `selem` is a deprecated argument name for `dilation`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  masks = [dilation(mask, selem=selem) for mask in masks]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "165523.png\n",
      "4818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 17:53:33.684861: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "output:\n",
      "\u001b[31m9641\u001b[0m\n",
      "----\n",
      "\u001b[31m2392\u001b[0m\n",
      "----\n",
      "\u001b[31m193\u001b[0m\n",
      "----\n",
      "\u001b[31m6626\u001b[0m\n",
      "----\n",
      "\u001b[31m3830\u001b[0m\n",
      "----\n",
      "input:\n",
      "025113.png\n",
      "227\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "output:\n",
      "\u001b[31m193\u001b[0m\n",
      "----\n",
      "\u001b[31m1878\u001b[0m\n",
      "----\n",
      "\u001b[31m193\u001b[0m\n",
      "----\n",
      "\u001b[31m8865\u001b[0m\n",
      "----\n",
      "\u001b[31m3784\u001b[0m\n",
      "----\n",
      "input:\n",
      "138624.png\n",
      "3658\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "output:\n",
      "\u001b[31m9586\u001b[0m\n",
      "----\n",
      "\u001b[31m5081\u001b[0m\n",
      "----\n",
      "\u001b[31m7932\u001b[0m\n",
      "----\n",
      "\u001b[31m4632\u001b[0m\n",
      "----\n",
      "\u001b[31m9586\u001b[0m\n",
      "----\n",
      "input:\n",
      "065245.png\n",
      "6480\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "output:\n",
      "\u001b[31m3668\u001b[0m\n",
      "----\n",
      "\u001b[31m3668\u001b[0m\n",
      "----\n",
      "\u001b[31m2346\u001b[0m\n",
      "----\n",
      "\u001b[31m946\u001b[0m\n",
      "----\n",
      "\u001b[31m8308\u001b[0m\n",
      "----\n",
      "input:\n",
      "059594.png\n",
      "9701\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "output:\n",
      "\u001b[31m5703\u001b[0m\n",
      "----\n",
      "\u001b[31m3780\u001b[0m\n",
      "----\n",
      "\u001b[31m249\u001b[0m\n",
      "----\n",
      "\u001b[31m3871\u001b[0m\n",
      "----\n",
      "\u001b[31m4286\u001b[0m\n",
      "----\n",
      "input:\n",
      "070660.png\n",
      "7118\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "output:\n",
      "\u001b[31m1558\u001b[0m\n",
      "----\n",
      "\u001b[31m6617\u001b[0m\n",
      "----\n",
      "\u001b[31m8536\u001b[0m\n",
      "----\n",
      "\u001b[31m132\u001b[0m\n",
      "----\n",
      "\u001b[31m1049\u001b[0m\n",
      "----\n",
      "input:\n",
      "003856.png\n",
      "3784\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "output:\n",
      "\u001b[32m3784\u001b[0m\n",
      "----\n",
      "\u001b[32m3784\u001b[0m\n",
      "----\n",
      "\u001b[31m2896\u001b[0m\n",
      "----\n",
      "\u001b[31m2896\u001b[0m\n",
      "----\n",
      "\u001b[32m3784\u001b[0m\n",
      "----\n",
      "input:\n",
      "076563.png\n",
      "3226\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "output:\n",
      "\u001b[31m5703\u001b[0m\n",
      "----\n",
      "\u001b[31m5544\u001b[0m\n",
      "----\n",
      "\u001b[31m7665\u001b[0m\n",
      "----\n",
      "\u001b[31m1785\u001b[0m\n",
      "----\n",
      "\u001b[31m6031\u001b[0m\n",
      "----\n",
      "input:\n",
      "047755.png\n",
      "6515\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "output:\n",
      "\u001b[31m1785\u001b[0m\n",
      "----\n",
      "\u001b[31m3464\u001b[0m\n",
      "----\n",
      "\u001b[31m3464\u001b[0m\n",
      "----\n",
      "\u001b[31m1375\u001b[0m\n",
      "----\n",
      "\u001b[31m1375\u001b[0m\n",
      "----\n",
      "input:\n",
      "166957.png\n",
      "4069\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "output:\n",
      "\u001b[31m7932\u001b[0m\n",
      "----\n",
      "\u001b[31m227\u001b[0m\n",
      "----\n",
      "\u001b[31m2999\u001b[0m\n",
      "----\n",
      "\u001b[31m2570\u001b[0m\n",
      "----\n",
      "\u001b[31m6894\u001b[0m\n",
      "----\n",
      "input:\n",
      "001714.png\n",
      "5703\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "output:\n",
      "\u001b[32m5703\u001b[0m\n",
      "----\n",
      "\u001b[31m5327\u001b[0m\n",
      "----\n",
      "\u001b[32m5703\u001b[0m\n",
      "----\n",
      "\u001b[32m5703\u001b[0m\n",
      "----\n",
      "\u001b[31m8018\u001b[0m\n",
      "----\n",
      "input:\n",
      "163813.png\n",
      "4518\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "output:\n",
      "\u001b[31m2390\u001b[0m\n",
      "----\n",
      "\u001b[31m3668\u001b[0m\n",
      "----\n",
      "\u001b[32m4518\u001b[0m\n",
      "----\n",
      "\u001b[32m4518\u001b[0m\n",
      "----\n",
      "\u001b[31m2390\u001b[0m\n",
      "----\n",
      "input:\n",
      "010143.png\n",
      "2961\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "output:\n",
      "\u001b[31m7123\u001b[0m\n",
      "----\n",
      "\u001b[31m4078\u001b[0m\n",
      "----\n",
      "\u001b[31m6031\u001b[0m\n",
      "----\n",
      "\u001b[31m6031\u001b[0m\n",
      "----\n",
      "\u001b[31m3276\u001b[0m\n",
      "----\n",
      "input:\n",
      "061962.png\n",
      "910\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "output:\n",
      "\u001b[31m203\u001b[0m\n",
      "----\n",
      "\u001b[31m8666\u001b[0m\n",
      "----\n",
      "\u001b[31m249\u001b[0m\n",
      "----\n",
      "\u001b[31m9193\u001b[0m\n",
      "----\n",
      "\u001b[31m5544\u001b[0m\n",
      "----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [40], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m index_of_test\u001b[38;5;241m=\u001b[39mimg_names\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m      8\u001b[0m input_folder\u001b[38;5;241m=\u001b[39mimg_folders[index_of_test] \n\u001b[0;32m----> 9\u001b[0m salient\u001b[38;5;241m=\u001b[39m\u001b[43mslc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetSaliency\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata-set/celeba/Clean/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m65\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28minput\u001b[39m)\n",
      "Cell \u001b[0;32mIn [12], line 39\u001b[0m, in \u001b[0;36mSaliency.GetSaliency\u001b[0;34m(self, input, trs)\u001b[0m\n\u001b[1;32m     37\u001b[0m call_model_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_idx_str: prediction_class}\n\u001b[1;32m     38\u001b[0m xrai_object \u001b[38;5;241m=\u001b[39m saliency\u001b[38;5;241m.\u001b[39mXRAI()\n\u001b[0;32m---> 39\u001b[0m xrai_attributions \u001b[38;5;241m=\u001b[39m \u001b[43mxrai_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetMask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_model_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_model_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m mask \u001b[38;5;241m=\u001b[39m xrai_attributions \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(xrai_attributions, trs)\n\u001b[1;32m     41\u001b[0m im_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(im_orig)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/saliency/core/xrai.py:356\u001b[0m, in \u001b[0;36mXRAI.GetMask\u001b[0;34m(self, x_value, call_model_function, call_model_args, baselines, segments, base_attribution, batch_size, extra_parameters)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mGetMask\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    287\u001b[0m             x_value,\n\u001b[1;32m    288\u001b[0m             call_model_function,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m             batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    294\u001b[0m             extra_parameters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    295\u001b[0m   \u001b[39m\"\"\"Applies XRAI method on an input image and returns the result saliency heatmap.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \n\u001b[1;32m    297\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39m  TODO(tolgab) Add output_selector functionality from XRAI API doc\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mGetMaskWithDetails(x_value,\n\u001b[1;32m    357\u001b[0m                                     call_model_function,\n\u001b[1;32m    358\u001b[0m                                     call_model_args\u001b[39m=\u001b[39;49mcall_model_args,\n\u001b[1;32m    359\u001b[0m                                     baselines\u001b[39m=\u001b[39;49mbaselines,\n\u001b[1;32m    360\u001b[0m                                     segments\u001b[39m=\u001b[39;49msegments,\n\u001b[1;32m    361\u001b[0m                                     base_attribution\u001b[39m=\u001b[39;49mbase_attribution,\n\u001b[1;32m    362\u001b[0m                                     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    363\u001b[0m                                     extra_parameters\u001b[39m=\u001b[39;49mextra_parameters)\n\u001b[1;32m    364\u001b[0m   \u001b[39mreturn\u001b[39;00m results\u001b[39m.\u001b[39mattribution_mask\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/saliency/core/xrai.py:453\u001b[0m, in \u001b[0;36mXRAI.GetMaskWithDetails\u001b[0;34m(self, x_value, call_model_function, call_model_args, baselines, segments, base_attribution, batch_size, extra_parameters)\u001b[0m\n\u001b[1;32m    450\u001b[0m _logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mComputing IG...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    451\u001b[0m x_baselines \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_baselines(x_value, baselines)\n\u001b[0;32m--> 453\u001b[0m attrs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_integrated_gradients(x_value,\n\u001b[1;32m    454\u001b[0m                                        call_model_function,\n\u001b[1;32m    455\u001b[0m                                        call_model_args\u001b[39m=\u001b[39;49mcall_model_args,\n\u001b[1;32m    456\u001b[0m                                        baselines\u001b[39m=\u001b[39;49mx_baselines,\n\u001b[1;32m    457\u001b[0m                                        steps\u001b[39m=\u001b[39;49mextra_parameters\u001b[39m.\u001b[39;49msteps,\n\u001b[1;32m    458\u001b[0m                                        batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[1;32m    459\u001b[0m \u001b[39m# Merge attributions from different baselines.\u001b[39;00m\n\u001b[1;32m    460\u001b[0m attr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(attrs, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/saliency/core/xrai.py:259\u001b[0m, in \u001b[0;36mXRAI._get_integrated_gradients\u001b[0;34m(self, im, call_model_function, call_model_args, baselines, steps, batch_size)\u001b[0m\n\u001b[1;32m    256\u001b[0m grads \u001b[39m=\u001b[39m []\n\u001b[1;32m    257\u001b[0m \u001b[39mfor\u001b[39;00m baseline \u001b[39min\u001b[39;00m baselines:\n\u001b[1;32m    258\u001b[0m   grads\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 259\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_integrated_gradients\u001b[39m.\u001b[39;49mGetMask(\n\u001b[1;32m    260\u001b[0m           im,\n\u001b[1;32m    261\u001b[0m           call_model_function,\n\u001b[1;32m    262\u001b[0m           call_model_args\u001b[39m=\u001b[39;49mcall_model_args,\n\u001b[1;32m    263\u001b[0m           x_baseline\u001b[39m=\u001b[39;49mbaseline,\n\u001b[1;32m    264\u001b[0m           x_steps\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m    265\u001b[0m           batch_size\u001b[39m=\u001b[39;49mbatch_size))\n\u001b[1;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m grads\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/saliency/core/integrated_gradients.py:73\u001b[0m, in \u001b[0;36mIntegratedGradients.GetMask\u001b[0;34m(self, x_value, call_model_function, call_model_args, x_baseline, x_steps, batch_size)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(x_step_batched) \u001b[39m==\u001b[39m batch_size \u001b[39mor\u001b[39;00m alpha \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     72\u001b[0m   x_step_batched \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x_step_batched)\n\u001b[0;32m---> 73\u001b[0m   call_model_output \u001b[39m=\u001b[39m call_model_function(\n\u001b[1;32m     74\u001b[0m       x_step_batched,\n\u001b[1;32m     75\u001b[0m       call_model_args\u001b[39m=\u001b[39;49mcall_model_args,\n\u001b[1;32m     76\u001b[0m       expected_keys\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpected_keys)\n\u001b[1;32m     78\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_and_check_call_model_output(call_model_output,\n\u001b[1;32m     79\u001b[0m                                           x_step_batched\u001b[39m.\u001b[39mshape,\n\u001b[1;32m     80\u001b[0m                                           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_keys)\n\u001b[1;32m     82\u001b[0m   total_gradients \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m call_model_output[INPUT_OUTPUT_GRADIENTS]\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn [12], line 24\u001b[0m, in \u001b[0;36mSaliency.call_model_function\u001b[0;34m(self, images, call_model_args, expected_keys)\u001b[0m\n\u001b[1;32m     22\u001b[0m     _, output_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(images)\n\u001b[1;32m     23\u001b[0m     output_layer \u001b[38;5;241m=\u001b[39m output_layer[:,target_class_idx]\n\u001b[0;32m---> 24\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {saliency\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mINPUT_OUTPUT_GRADIENTS: gradients}\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1100\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1094\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[1;32m   1095\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1096\u001b[0m           output_gradients))\n\u001b[1;32m   1097\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1098\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1100\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[1;32m   1101\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[1;32m   1102\u001b[0m     flat_targets,\n\u001b[1;32m   1103\u001b[0m     flat_sources,\n\u001b[1;32m   1104\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[1;32m   1105\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[1;32m   1106\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[1;32m   1109\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[1;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m     target,\n\u001b[1;32m     70\u001b[0m     sources,\n\u001b[1;32m     71\u001b[0m     output_gradients,\n\u001b[1;32m     72\u001b[0m     sources_raw,\n\u001b[1;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/ops/nn_grad.py:587\u001b[0m, in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    568\u001b[0m shape_0, shape_1 \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mshape_n([op\u001b[39m.\u001b[39minputs[\u001b[39m0\u001b[39m], op\u001b[39m.\u001b[39minputs[\u001b[39m1\u001b[39m]])\n\u001b[1;32m    570\u001b[0m \u001b[39m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[39m# functions for performance reasons in Eager mode. gen_nn_ops functions take a\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[39m# `explicit_paddings` parameter, but nn_ops functions do not. So if we were\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39m# to use the nn_ops functions, we would have to convert `padding` and\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[39m# in Eager mode.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    577\u001b[0m     gen_nn_ops\u001b[39m.\u001b[39mconv2d_backprop_input(\n\u001b[1;32m    578\u001b[0m         shape_0,\n\u001b[1;32m    579\u001b[0m         op\u001b[39m.\u001b[39minputs[\u001b[39m1\u001b[39m],\n\u001b[1;32m    580\u001b[0m         grad,\n\u001b[1;32m    581\u001b[0m         dilations\u001b[39m=\u001b[39mdilations,\n\u001b[1;32m    582\u001b[0m         strides\u001b[39m=\u001b[39mstrides,\n\u001b[1;32m    583\u001b[0m         padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m    584\u001b[0m         explicit_paddings\u001b[39m=\u001b[39mexplicit_paddings,\n\u001b[1;32m    585\u001b[0m         use_cudnn_on_gpu\u001b[39m=\u001b[39muse_cudnn_on_gpu,\n\u001b[1;32m    586\u001b[0m         data_format\u001b[39m=\u001b[39mdata_format),\n\u001b[0;32m--> 587\u001b[0m     gen_nn_ops\u001b[39m.\u001b[39;49mconv2d_backprop_filter(\n\u001b[1;32m    588\u001b[0m         op\u001b[39m.\u001b[39;49minputs[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    589\u001b[0m         shape_1,\n\u001b[1;32m    590\u001b[0m         grad,\n\u001b[1;32m    591\u001b[0m         dilations\u001b[39m=\u001b[39;49mdilations,\n\u001b[1;32m    592\u001b[0m         strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[1;32m    593\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m    594\u001b[0m         explicit_paddings\u001b[39m=\u001b[39;49mexplicit_paddings,\n\u001b[1;32m    595\u001b[0m         use_cudnn_on_gpu\u001b[39m=\u001b[39;49muse_cudnn_on_gpu,\n\u001b[1;32m    596\u001b[0m         data_format\u001b[39m=\u001b[39;49mdata_format)\n\u001b[1;32m    597\u001b[0m ]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/ops/gen_nn_ops.py:1080\u001b[0m, in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   1079\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   1081\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mConv2DBackpropFilter\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39minput\u001b[39;49m, filter_sizes, out_backprop,\n\u001b[1;32m   1082\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mstrides\u001b[39;49m\u001b[39m\"\u001b[39;49m, strides, \u001b[39m\"\u001b[39;49m\u001b[39muse_cudnn_on_gpu\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_cudnn_on_gpu, \u001b[39m\"\u001b[39;49m\u001b[39mpadding\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1083\u001b[0m       padding, \u001b[39m\"\u001b[39;49m\u001b[39mexplicit_paddings\u001b[39;49m\u001b[39m\"\u001b[39;49m, explicit_paddings, \u001b[39m\"\u001b[39;49m\u001b[39mdata_format\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1084\u001b[0m       data_format, \u001b[39m\"\u001b[39;49m\u001b[39mdilations\u001b[39;49m\u001b[39m\"\u001b[39;49m, dilations)\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   1086\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count_of_true=0\n",
    "count_of_false=0\n",
    "count_of_all=0\n",
    "AllData=[['input','output1','output2','output3','output4','output5']]\n",
    "\n",
    "for input in test: \n",
    "    index_of_test=img_names.index(input)\n",
    "    input_folder=img_folders[index_of_test] \n",
    "    salient=slc.GetSaliency(('data-set/celeba/Clean/'+input), 65)\n",
    "    \n",
    "    print('input:')\n",
    "    print(input)\n",
    "    print(input_folder) \n",
    "\n",
    "    # imgplot = plt.imshow(salient)\n",
    "    arr2im = PIL.Image.fromarray(salient)\n",
    "    salient = arr2im.resize((224,224))\n",
    "    salient = np.asarray(salient)\n",
    "    salient_feature=fe.extract_by_array(salient)\n",
    "    input_ssa=SSA_H_Plus(salient_feature)\n",
    "    thisrec=[input_folder]  \n",
    "    # plt.show() \n",
    "    score_of_trained=[]\n",
    "    for trained in training:\n",
    "        index_of_trained=img_names.index(trained)\n",
    "        trained_ssa=SSA_features[index_of_trained]\n",
    "        distance= sqrt( sum(np.multiply(trained_ssa - input_ssa,trained_ssa - input_ssa)))\n",
    "        trained_folder=img_folders[index_of_trained]\n",
    "        score_of_trained.append([distance,trained,trained_folder])\n",
    "    score_of_trained.sort()\n",
    "    score_of_trained=score_of_trained[:count_of_results]\n",
    "    new_rec={\n",
    "        'input':input\n",
    "        ,'class':input_folder,\n",
    "        'output':[{'name':x[1],'class':x[2]} for x in score_of_trained]\n",
    "    } \n",
    "    print('output:')\n",
    "    for res in score_of_trained: \n",
    "        if(res[2]==input_folder):\n",
    "            print(colored(res[2],'green'))\n",
    "            count_of_true=count_of_true+1\n",
    "        else:\n",
    "            print(colored(res[2],'red'))\n",
    "            count_of_false=count_of_false+1\n",
    "        count_of_all=count_of_all+1\n",
    "        thisrec.append(res[2])\n",
    "        \n",
    "        # img=mpimg.imread(os.getcwd()+'/data-set/dogs/images/Images/'+res[2]+'/'+res[1])\n",
    "        # imgplot=plt.imshow(img)\n",
    "        # plt.show() \n",
    "        print('----')\n",
    "    AllData.append(thisrec)    \n",
    "AllData.append([count_of_all,0,0,0,0,count_of_true])\n",
    "print('Count Of True: '+str(count_of_true))\n",
    "print('Count Of False: '+str(count_of_false))\n",
    "print('Count Of All: '+str(count_of_all))\n",
    "table = tabulate.tabulate(AllData, tablefmt='html')\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
